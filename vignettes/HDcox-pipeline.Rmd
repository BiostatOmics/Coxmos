---
title: "Step-by-step guide to the HDcox pipeline"
author: 
    name: "Pedro Salguero GarcÃ­a"
    affiliation: "Institute for Integrative Systems Biology (I2SysBio) and Polytechnic University of Valencia, Valencia, Spain"
    email: pedrosalguerog@gmail.com
package: HDcox
date: "Last updated: `r format(Sys.time(), '%d %B, %Y')`"
output: 
    rmarkdown::html_vignette:
        toc: true
vignette: >
  %\VignetteIndexEntry{Step-by-step guide to the HDcox pipeline}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<style type="text/css">
.main-container {
  max-width: 1080px !important;
  margin-left: auto;
  margin-right: auto;
}

body {
  max-width: 1080px !important;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r, include = FALSE}
dpi = 125

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dpi=dpi, 
  fig.retina=1, 
  fig.width=1440/dpi, #4:3 FHD
  fig.height=1080/dpi, 
  out.width="100%",
  crop = NULL,
  warning = T, 
  error = T
)

rm(dpi)
```

# Introduction

The **HDcox** R package contains the necessary functions to reproduce the
pipeline in [this paper*](),
a study by *Salguero-Garcia et al.* in which we analyze ....

The pipeline includes ... basic analysis blocks:

1. **Cross-validation and performing survival models for high dimensional data sets**. First, ... 

2. **Comparing multiple survival models**. ...

3. **Understanding the results in terms of the original variables**. ...

# Installation

HDcox can be installed from GitHub using `devtools`:

```{r, eval=FALSE}
install.packages("devtools")
devtools::install_github("ConesaLab/HDcox", build_vignettes = TRUE)
```

# Getting ready

To run the analyses in this vignette, you'll first need to load `HDcox`:

```{r setup, results = "hide"}
# load HDcox
library(HDcox)
```

In addition, we'll require some additional packages for data formatting. Most of them are signaled as `HDcox` dependencies, 
so they will already be installed in your system.

To generate plots, we make use of the `RColorConesa` R package.
After install:

```{r, eval=FALSE}
# install.packages("devtools")
devtools::install_github("ConesaLab/RColorConesa")
```

...you can load and set the theme of your R session as follows:

```{r}
library(RColorConesa)
#theme_set(theme_colorConesa()) #under development
```

# Input data

The HDcox pipeline requires two matrices as input. First one must be the features under study, and the second one a matrix with two columns called **time** and **event** for survival information.

To generate the matrices, we first processed the data from ... Details to this process can be found in [our manuscript]() 
(see Supplementary Note and Methods).

If you wish to reproduce the analyses in Salguero-Garcia et al. [[1]](#1)), you can load the
`data_E.MTAB.386.RData` object. After quality control (see Methods in [Salguero-Garcia et al.]() 
[[1]](#1))the data contains expression data for **126 observations** 
and **10357 genes**. However, for this vignette we are going to load a small version of the dataset with **126 observations** and only **500 genes** as follows:

```{r}
# load Tasic dataset
data("X_small_data_E.MTAB.386")
data("Y_small_data_E.MTAB.386")

X <- X_small_data_E.MTAB.386
Y <- Y_small_data_E.MTAB.386

rm(X_small_data_E.MTAB.386, Y_small_data_E.MTAB.386)
```

**X** and **Y** are two `data.frame` objects. **X** is related to the explanatory variables. Rows are observations and columns are the different variables of interest. For **Y** matrix, rows are the observations with the same row names as **X**, and it has to have two columns. The first one "time" and the second one "event". "time" refers to the following up time until the event or until the last control if the observation is a right censored observation. The event could be TRUE/FALSE or 1/0 for those observations that have reach the event or are censored. An example could be show in the next code:

```{r, echo = FALSE}
knitr::kable(X[1:5,1:5])

knitr::kable(Y[1:5,])
```
As we said, the dimension of each object is 126x500 for **X** matrix, and 126x2 for **Y** matrix.

```{r, echo = FALSE}
knitr::kable(dim(X), col.names = "X")
knitr::kable(dim(Y), col.names = "Y")
```

**HDcox** has a series of plots to understand the distribution of the data. One of them is the plot of events along time. The function requires the Y matrix. As optional arguments, the user can specify: 

1. *max.breaks* Number of breaks for the histogram. 
2. *roundTo* the minimum numeric value for round break-times values. E.g. 0.25, a value of 1.32 will be rounded to 1.25 (numbers shall be rounded off to multipliers of 0.25).
1. *categories* the name for each category (character vector of length two)
2. *y.text* the name for the y axis

```{r}
ggp_density.event <- plot_events(Y = Y, 
                                 categories = c("Censored","Death"), #name for FALSE/0 (Censored) and TRUE/1 (Event)
                                 y.text = "Number of observations", 
                                 roundTo = 0.5, 
                                 max.breaks = 10) 
```

```{r fig.small = T}
ggp_density.event$plot
```

# Survival models for low/high dimensional data sets

After loading the data, it may be of interest for the user to perform a survival analysis in order to examine the relationship between explanatory variables and the outcome. However, traditional methods are only applicable for low-dimensional datasets. To address this issue, we have developed a set of functions that utilize (s)PLS techniques in combination with Cox analysis for the analysis of high-dimensional datasets.

*HDcox* provides the following methodologies:

* Classical approaches: COX, COX StepWise and COX Elastic Net.
* PLS approaches: PLS-ICOX, sPLS-DRCOX, sPLS-DRCOX-MixOmics and sPLS-DACOX-MixOmics.

More information for each approach could be found in the help section for each function. The function name for each methodology are:

* Classical approaches: cox, coxSW and coxEN.
* PLS approaches: plsicox, splsdrcox, splsdrcox_mixOmics and splsdacox_mixOmics.

To perform a survival analysis with our example, we will use methodologies that can work with high-dimensional data. These are the set of methodologies that use PLS and COX Elastic Net techniques.

The first thing we are going to do is split our data into a training set and a test set. This split will be made with a proportion of 80% of the data for training and 20% for test.

## TRAIN/TEST

First, we will divide our data into a training and testing set using the `createDataPartition` function from the R package caret. We will use a 80%/20% split for training and testing, respectively, and set a seed for reproducible results.

```{r}
set.seed(123)
index_train <- caret::createDataPartition(Y$event,
                                          p = .8, #80% train
                                          list = FALSE,
                                          times = 1)

X_train <- X[index_train,] #101x500
Y_train <- Y[index_train,]
X_test <- X[-index_train,] #25x500
Y_test <- Y[-index_train,]
```

## Clasical approach

We have already mentioned that we need to work with a high-dimensional methodology. However, if we try to run a classical analysis with one of our functions such as a Cox analysis using the entire matrix X, we will get an error due to the specification of the MIN_EPV parameter. This parameter, set by default to 5, establishes a minimum ratio of variables that should be included in a survival model according to the number of patients who experience the event (Events / Variables of X). According to literature, values greater than 10 should be used to obtain models with good predictions, but this value should not be lower than 5.

```{r, eval=FALSE, message=T, error=F}
# classical approach
cox_model <- cox(X = X_train, Y = Y_train, 
                 x.center = T, x.scale = F, 
                 y.center = F, y.scale = F, 
                 remove_near_zero_variance = T, remove_zero_variance = T, toKeep.zv = NULL, 
                 remove_non_significant = F, alpha = 0.05, 
                 MIN_EPV = 5, FORCE = F, returnData = T, verbose = T)
```

Despite specifying an EPV of 5, we should have a maximum of 9 variables in our final survival model in relation to the number of events found in our training set. To compute our EPV, we can used the function `getEPV()` that requires the matrix X and Y as input.

```{r}
EPV <- getEPV(X_train, Y_train)
EPV
```
As previously mentioned, our data set is high dimensional in terms of variables and patients, but also has an EPV value of `r EPV`, which is much lower than the recommended value in the literature.

Once the problem has been demonstrated, we will proceed to launch the methods that allow us to work with high dimensionality. For this, it will not only be necessary to launch the methods themselves that calculate the survival model, but also a cross validation to estimate the optimal values for each methodology.

## Cross Validation

In order to perform survival analysis with our high-dimensional data, we have implemented a series of methods that utilize techniques such as Cox Elastic Net and partial least squares (PLS). To evaluate the performance of these methods, we have implemented cross-validation, which allows us to estimate the optimal parameters for future predictions based on metrics such as AIC, C-INDEX, and AUC. By default AUC metric is used with the "cenROC" evaluator as it has provided the best results in our tests. However, the multiple metrics could be used changed the weights in their parameters. Furthermore, other evaluators have been implemented ("risksetROC", "survivalROC", "cenROC", "nsROC", "smoothROCtime_C" and "smoothROCtime_I").

In addition, we have included options for normalizing data, filtering variables, and setting the minimum EPV, as well as specific parameters for each method, such as the alpha value for Cox Elastic Net and the number of components for PLS models. Overall, our cross-validation methodology allows us to effectively analyze high-dimensional survival data and optimize our model parameters.

## Cox Elastic Net

Cox Elastic Net is based on the R package "glmnet" for survival analysis. However, the structure of the object and the way the analysis is performed has been updated by using our cross-validation methodology to estimate the optimal parameters for future predictions.

During the cross validation, we will iterate over the different alpha values between 0 and 1 (lasso and ridge regression) and as maximum number of variables we select the dimension of the X matrix itself. However, since the EPV requirement will not be met, the number of variables will be limited to the maximum of 9, as previously determined.

```{r, eval=FALSE, warning=F}
# run cv.coxEN
cv.coxen_res <- cv.coxEN(X = X_train, Y = Y_train, 
                         EN.alpha.list = seq(0,1,0.1),
                         max.variables = ncol(X_train),
                         n_run = 2, k_folds = 10, 
                         x.center = T, x.scale = F, 
                         y.center = F, y.scale = F,
                         remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL,
                         remove_non_significant = F, alpha = 0.05, 
                         w_AIC = 0,  w_c.index = 0, w_AUC = 1, times = NULL,
                         MIN_AUC_INCREASE = 0.05, MIN_AUC = 0.8, MIN_COMP_TO_CHECK = 3,
                         pred.attr = "mean", pred.method = "cenROC", fast_mode = F,
                         MIN_EPV = 5, return_models = F,
                         PARALLEL = T, verbose = F, seed = 123)
cv.coxen_res #1.5min.
```

```{r}
coxen_model <- coxEN(X = X_train, Y = Y_train, 
                     EN.alpha = 0, #cv.coxen_res$opt.EN.alpha
                     max.variables = 8, #cv.coxen_res$opt.nvar
                     x.center = T, x.scale = F, 
                     y.center = F, y.scale = F, 
                     remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL, 
                     remove_non_significant = F, alpha = 0.05, 
                     MIN_EPV = 5, returnData = T, verbose = F)

coxen_model
```
As can be seen in the resulting cox model, some of the selected variables have not been significant. If we wish to calculate a model where all selected variables are significant, we should update the remove_non_significant parameter to TRUE.

```{r}
coxen_model <- coxEN(X = X_train, Y = Y_train, 
                     EN.alpha = 0, #cv.coxen_res$opt.EN.alpha
                     max.variables = 8, #cv.coxen_res$opt.nvar
                     x.center = T, x.scale = F, 
                     y.center = F, y.scale = F, 
                     remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL, 
                     remove_non_significant = T, alpha = 0.05, 
                     MIN_EPV = 5, returnData = T, verbose = F)

coxen_model
```

## PLS-ICOX

In the same way, we will also perform a cross validation for the PLS-based models, starting with the PLS-ICOX methodology. In this case, the internal construction of the weights of the PLS model for the calculation of the components of the X matrix is based on univariate cox models. After this, we are able to reduce the dimensionality of our data set to ultimately launch a cox model with the latent variables or principal components of the PLS model.

```{r, eval=FALSE, message=F}
# run cv.plsicox
cv.plsicox_res <- cv.plsicox(X = X_train, Y = Y_train,
                             max.ncomp =  10,
                             n_run = 2, k_folds = 10, 
                             x.center = T, x.scale = F, 
                             y.center = F, y.scale = F,
                             remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL,
                             remove_non_significant_models = F, alpha = 0.05, 
                             w_AIC = 0,  w_c.index = 0, w_AUC = 1, times = NULL,
                             MIN_AUC_INCREASE = 0.05, MIN_AUC = 0.8, MIN_COMP_TO_CHECK = 3,
                             pred.attr = "mean", pred.method = "cenROC", fast_mode = F,
                             MIN_EPV = 5, return_models = F,
                             PARALLEL = T, verbose = F, seed = 123)
cv.plsicox_res #3.7min.
```

```{r, eval=FALSE, fig.small=T}
# plot cv.plsicox
cv.plsicox_res$plot_AUC
```

We will generate a PLS-ICOX model with a total of two principal components based on the results obtained from the cross validation.

```{r}
plsicox_model <- plsicox(X = X_train, Y = Y_train, 
                         n.comp = 2, #n.comp = cv.plsicox_res$opt.comp
                         x.center = T, x.scale = F,
                         y.center = F, y.scale = F,
                         remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL,
                         tol = 500, 
                         MIN_EPV = 5, returnData = T, verbose = F)

plsicox_model
```

## sPLS-DRCOX

Next, we will perform a cross validation for the sPLS-DRCOX methodology. In this case, an sPLS model is run using the deviance residuals of a null Cox model as the Y matrix. The penalties for variable selection follow the strategy used in the R package "plsRcox" from which the idea for the methodology was derived.

```{r, eval=FALSE, message=F}
# run cv.splsdrcox
cv.splsdrcox_res <- cv.splsdrcox(X = X_train, Y = Y_train, 
                                 max.ncomp = 10, eta.list = seq(0,0.5,0.25), #penalty
                                 n_run = 2, k_folds = 10, 
                                 x.center = T, x.scale = F, 
                                 y.center = F, y.scale = F,
                                 remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL,
                                 remove_non_significant_models = F, alpha = 0.05, 
                                 w_AIC = 0,  w_c.index = 0, w_AUC = 1, times = NULL,
                                 MIN_AUC_INCREASE = 0.05, MIN_AUC = 0.8, MIN_COMP_TO_CHECK = 3,
                                 pred.attr = "mean", pred.method = "cenROC", fast_mode = F,
                                 MIN_EPV = 5, return_models = F,
                                 PARALLEL = T, verbose = F, seed = 123)

cv.splsdrcox_res #2min 40s.
```

"Based on the results obtained through cross validation, we will create a PLS-DRCOX model with a single component and no eta penalty as seen in the cross validation.

```{r}
splsdrcox_model <- splsdrcox(X = X_train, Y = Y_train, 
                             n.comp = 1, eta = 0, #n.comp = cv.splsdrcox_res$opt.comp, eta = cv.splsdrcox_res$opt.eta
                             x.center = T, x.scale = F,
                             y.center = F, y.scale = F,
                             remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL,
                             MIN_EPV = 5, returnData = T, verbose = F)

splsdrcox_model
```

## sPLS-DRCOX MixOmics Penalty

For sPLS-DRCOX methodology we implemented another kind of penalty based on an heuristic variable selection and the MixOmics algorithms. In this case, the penalty is based on a vector of variables. We can select a specific value to select that number of variables, but if we keep the value in NULL, the number of variable will be selected automaticly.

```{r, eval=FALSE, message=F}
# run cv.splsdrcox
cv.splsdrcox_mo_res <- cv.splsdrcox_mixOmics(X = X_train, Y = Y_train, 
                                             max.ncomp = 10, vector = NULL,
                                             n_run = 2, k_folds = 10, 
                                             x.center = T, x.scale = F, 
                                             y.center = F, y.scale = F,
                                             remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL,
                                             remove_non_significant_models = F, alpha = 0.05, 
                                             w_AIC = 0,  w_c.index = 0, w_AUC = 1, times = NULL,
                                             MIN_AUC_INCREASE = 0.05, MIN_AUC = 0.8, MIN_COMP_TO_CHECK = 3,
                                             pred.attr = "mean", pred.method = "cenROC", fast_mode = F,
                                             MIN_EPV = 5, return_models = F,
                                             PARALLEL = T, verbose = F, seed = 123)

cv.splsdrcox_mo_res #2min 40s.
```

## PLS-DACOX

Also we are going to run cross-validation techniques for PLSDACOX of the PLS methods.

```{r, eval=FALSE, message=F}
# run cv.splsdrcox
cv.splsdacox_res <- cv.splsdacox_mixOmics(X = X_train, Y = Y_train, 
                                          max.ncomp = 4,  vector = NULL,
                                          n_run = 2, k_folds = 10, 
                                          x.center = T, x.scale = F, 
                                          y.center = F, y.scale = F,
                                          remove_near_zero_variance = T, remove_zero_variance = F, toKeep.zv = NULL,
                                          remove_non_significant_models = F, alpha = 0.05, 
                                          w_AIC = 0,  w_c.index = 0, w_AUC = 1, times = NULL,
                                          MIN_AUC_INCREASE = 0.05, MIN_AUC = 0.8, MIN_COMP_TO_CHECK = 3,
                                          pred.attr = "mean", pred.method = "cenROC", fast_mode = F,
                                          MIN_EPV = 5, return_models = F,
                                          PARALLEL = T, verbose = F, seed = 123)

cv.splsdacox_res #2min
```

So splsdacox_model ...

```{r}
splsdacox_model <- splsdacox_mixOmics(X = X_train, Y = Y_train, 
                                    n.comp = 3, #cv.splsdacox_res$opt.comp
                                    x.center = T, x.scale = F)

splsdacox_model
```

# Comparing multiple survival models

## Comparing for multiple evaluators at the same time.

```{r}
lst_models <- list("PLS-ICOX" = plsicox_model,
                   "SPLS-DRCOX" = splsdrcox_model,
                   "PLS-DACOX" = splsdacox_model)

eval_results <- eval_models4.0(lst_models = lst_models,
                               X_test = X_test, Y_test = Y_test, 
                               pred.method = "cenROC",
                               pred.attr = "mean",
                               times = seq(1,4,0.5), max_time_points = 15, 
                               PARALLEL = T)

# lst_evaluators <- c(cenROC = "cenROC", 
#                     risksetROC = "risksetROC")
# 
# eval_results <- purrr::map(lst_evaluators, ~eval_models4.0(lst_models = lst_models,
#                                                            X_test = X_test, Y_test = Y_test, 
#                                                            pred.method = .,
#                                                            pred.attr = "mean",
#                                                            times = seq(1,4,0.5), max_time_points = 15, 
#                                                            PARALLEL = T))
```

```{r}
eval_results
#eval_results$cenROC
```

## Plot comparison

```{r}
lst_eval_results <- plot_evaluation(eval_results)
#lst_eval_results <- plot_evaluation.list(eval_results)
```

```{r, fig.small=T}
lst_eval_results$lst_plots$lineplot.mean
lst_eval_results$lst_plot_comparisons$t.test

# lst_eval_results$cenROC$lst_plots$lineplot.mean
# lst_eval_results$cenROC$lst_plot_comparisons$t.test
```

## Computing time comparison (we use the cross validation models)

We should add the cross validations models in order to see which method takes more time.

```{r}
lst_models_time <- list(plsicox_model,
                        splsdrcox_model,
                        splsdacox_model,
                        eval_results)
```

```{r}
ggp_time <- plot_time.models(lst_models_time)
```

```{r, fig.small=T}
ggp_time
```

## Forest plots

```{r}
lst_forest_plot <- purrr::map(lst_models, ~survminer::ggforest(.$survival_model$fit, 
                                                               data = .$survival_model$fit$model))
```

```{r, fig.small=T}
lst_forest_plot$`SPLS-DRCOX`
```

## Density plots for each prediction

```{r}
density.plots.lp <- plot_cox.event.list(lst_models, type = "lp")
```

```{r, fig.small=T}
density.plots.lp$`SPLS-DRCOX`$plot.density
density.plots.lp$`SPLS-DRCOX`$plot.histogram
```

## PH Assumption

```{r}
lst_ph_ggplot <- plot_proportionalHazard.list(lst_models)
```

```{r, fig.small=T}
lst_ph_ggplot$`SPLS-DRCOX`
```

## Studying PLS model

```{r}
ggp_scores <- plot_PLS_HDcox(model = lst_models$`SPLS-DRCOX`, 
                             comp = c(1,2), mode = "scores")
```

```{r, fig.small=T}
ggp_scores$plot
```

```{r}
ggp_loadings <- plot_PLS_HDcox(model = lst_models$`SPLS-DRCOX`, 
                               comp = c(1,2), mode = "loadings",
                               top = 10) #length from 0,0
```

```{r, fig.small=T}
ggp_loadings$plot
```
```{r}
ggp_biplot <- plot_PLS_HDcox(model = lst_models$`SPLS-DRCOX`, 
                             comp = c(1,2), mode = "biplot",
                             top = 15,
                             only_top = T)
```

```{r, fig.small=T}
ggp_biplot$plot
```

# Understanding the results in terms of the original variables

## Psudobeta

```{r}
ggp.simulated_beta <- plot_pseudobeta.list(lst_models = lst_models, 
                                           error.bar = T, onlySig = T, alpha = 0.05, 
                                           zero.rm = T, auto.limits = T, top = 20,
                                           show_percentage = T, size_percentage = 3)
```

```{r, fig.small=T}
ggp.simulated_beta$`SPLS-DRCOX`$plot
```

## Kaplan-Meier

### Full model

```{r}
LST_KM_RES_LP <- getAutoKM.list(type = "LP",
                                lst_models = lst_models,
                                comp = 1:4,
                                top = 10,
                                ori_data = T,
                                BREAKTIME = NULL,
                                only_sig = T, alpha = 0.05)
```

```{r, fig.small=T}
LST_KM_RES_LP$`SPLS-DRCOX`$LST_PLOTS$LP
```

### Per components

```{r}
LST_KM_RES_COMP <- getAutoKM.list(type = "COMP",
                                  lst_models = lst_models,
                                  comp = 1:4,
                                  top = 10,
                                  ori_data = T,
                                  BREAKTIME = NULL,
                                  only_sig = T, alpha = 0.05)
```

```{r, fig.small=T}
LST_KM_RES_COMP$`SPLS-DRCOX`$LST_PLOTS$comp_1
LST_KM_RES_COMP$`SPLS-DRCOX`$LST_PLOTS$comp_2
```

### Per original variables

Matches psudobetas

```{r}
LST_KM_RES_VAR <- getAutoKM.list(type = "VAR",
                                 lst_models = lst_models,
                                 comp = 1:4,
                                 top = 10,
                                 ori_data = T,
                                 BREAKTIME = NULL,
                                 only_sig = T, alpha = 0.05)
```

```{r, fig.small=T}
LST_KM_RES_VAR$`SPLS-DRCOX`$LST_PLOTS$POSTN
LST_KM_RES_VAR$`SPLS-DRCOX`$LST_PLOTS$SIRT5
```

# New patients

```{r}
new_pat <- X_test[1,,drop=F]
```

```{r}
knitr::kable(Y_test[rownames(new_pat),])
```

```{r}
ggp.simulated_beta_newPat <- plot_pseudobeta_newPatient.list(lst_models = lst_models, 
                                                             new_pat = new_pat,
                                                             error.bar = T, onlySig = T, alpha = 0.05,
                                                             zero.rm = T, auto.limits = T, show.betas = T, top = 20)

# ggp.simulated_beta_newPat <- plot_pseudobeta_newPatient(model = lst_models$`SPLS-DRCOX`, 
#                                                         new_pat = new_pat,
#                                                         error.bar = T, onlySig = T, alpha = 0.05,
#                                                         zero.rm = T, auto.limits = T, show.betas = T, top = 20)
```

Opposite direction means its value is under the mean for risk one or over the mean for protective ones.

```{r, fig.small=T}
ggp.simulated_beta_newPat$`SPLS-DRCOX`$plot
```

## Add patient to density plot

```{r}
pat_density <- plot_patient.eventDensity(patient = new_pat, 
                                         time = NULL, 
                                         model = lst_models$`SPLS-DRCOX`, 
                                         type = "lp")
```

```{r, fig.small=T}
pat_density
```

```{r}
pat_histogram <- plot_patient.eventHistogram(patient = new_pat, 
                                             time = NULL, 
                                             model = lst_models$`SPLS-DRCOX`, 
                                             type = "lp")
```

```{r, fig.small=T}
pat_histogram
```

```{r, eval=F}
#plot_divergent.biplot - for num and qual variables
```

## COX compare multiple patients

```{r}
knitr::kable(Y_test[1:5,])
```
```{r}
lst_cox.comparison <- plot_LP.multiplePatients.list(lst_models = lst_models, 
                                     df.pat = X_test[1:5,], 
                                     error.bar = T, zero.rm = T, onlySig = T, alpha = 0.05, top = 5)
```

```{r, fig.small=T}
lst_cox.comparison$`SPLS-DRCOX`$plot
```
